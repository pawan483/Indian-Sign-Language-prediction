# Indian-Sign-Language-prediction
# Indian Sign Language Detection (Gradio App)

This project implements an **Indian Sign Language (ISL) hand sign detection system**
that classifies hand gestures (Aâ€“X) using a **Convolutional Neural Network (CNN)**.
The model is deployed with a **browser-based interface using Gradio**.

---

## ðŸš€ Features
- Image-based ISL hand sign classification (Aâ€“X)
- Deep learning model built using TensorFlow & Keras
- Interactive web interface using Gradio
- Browser-accessible demo via Google Colab

---

## ðŸ›  Tech Stack
- Python
- TensorFlow / Keras
- Gradio
- NumPy
- Pillow
- Google Colab

---

## ðŸ“ Project Structure
â”œâ”€â”€ app.py
â”œâ”€â”€ isl_model.h5
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
## â–¶ï¸ How to Run

### 1. Clone the repository 
git clone https://github.com/yourusername/indian-sign-language-gradio.git
cd indian-sign-language-gradio

## 2. install dependencies
pip install -r requirements.txt
## 3.Run the application 
python app.py

The Gradio interface will open in your browser at:

https://2eaffd1991430f4ccb.gradio.live
  ## Demo 
  
---

## ðŸŒ Demo

Explain clearly how the browser demo works.

## ðŸŒ Demo

This project provides a browser-based demo using **Gradio**.
When executed on **Google Colab**, a temporary public URL is generated using
Gradioâ€™s `share=True` option.

> Note: The public demo link is active only while the runtime is running.
> 
## ðŸ›  Tech Stack
- Python
- TensorFlow / Keras
- Gradio
- NumPy
- Pillow

## ðŸ“Œ Learning Outcomes
- Built a CNN-based image classification model
- Understood image preprocessing and normalization
- Learned to deploy ML models using Gradio
- Created browser-based demos for ML applications


